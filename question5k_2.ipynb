{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report as clrp\n",
    "kf = KFold(n_splits=5)\n",
    "df = pd.read_csv('fake_job_postings.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def lemmatize_text1(text):\n",
    "    return [lemmatizer.lemmatize(w,pos=\"v\") for w in w_tokenizer.tokenize(text)]\n",
    "def lemmatize_text2(text):\n",
    "    return [lemmatizer.lemmatize(w,pos=\"n\") for w in text]\n",
    "df_desc = df.description.fillna(' ').combine(df.requirements.fillna(' '), lambda x,y: x+y)\n",
    "df_desc= df_desc.str.replace('[^\\w\\s]','') #remove punctuation\n",
    "df_desc= df_desc.str.replace('\\d+', '') #remove numbers \n",
    "df_desc= df_desc.apply(lambda x: \" \".join(x.lower() for x in str(x).split())) #lowercase\n",
    "df_desc= df_desc.apply(lemmatize_text1)\n",
    "df_desc= df_desc.apply(lemmatize_text2)\n",
    "df_desc= df_desc.apply(lambda x: \" \".join(x for x in x if x not in stop)) #remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,3),max_features=200)\n",
    "sparse_matrix = vectorizer.fit_transform(df_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = sparse_matrix.todense()\n",
    "sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['job_id','title','location','department','company_profile','description','requirements','industry','function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('empty')\n",
    "df['salary_range'] = df.salary_range.apply(lambda x : 0 if x== 'empty' else 1)\n",
    "df['benefits'] = df.benefits.apply(lambda x : 0 if x == 'empty' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(sparse=False,drop = ['empty'])\n",
    "df1=onehotencoder.fit_transform(np.array(df.employment_type).reshape(-1,1))\n",
    "df1 = pd.DataFrame(df1)\n",
    "#df1 = df1.drop(columns = 0)\n",
    "for i in range(df1.shape[1]):\n",
    "    df['emp_type'+ str(i)] = df1.iloc[:,i]\n",
    "df = df.drop(columns = 'employment_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=onehotencoder.fit_transform(np.array(df.required_experience).reshape(-1,1))\n",
    "df1 = pd.DataFrame(df1)\n",
    "#df1 = df1.drop(columns = 0)\n",
    "for i in range(df1.shape[1]):\n",
    "    df['req_exp'+ str(i)] = df1.iloc[:,i]\n",
    "df = df.drop(columns = 'required_experience')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=onehotencoder.fit_transform(np.array(df.required_education).reshape(-1,1))\n",
    "df1 = pd.DataFrame(df1)\n",
    "#df1 = df1.drop(columns = 0)\n",
    "for i in range(df1.shape[1]):\n",
    "    df['req_edu'+ str(i)] = df1.iloc[:,i]\n",
    "df = df.drop(columns = 'required_education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_matrix = df.fraudulent\n",
    "xtrain_matrix = df.drop(columns = 'fraudulent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_matrix = np.array(xtrain_matrix)\n",
    "xtrain_matrix = np.concatenate((xtrain_matrix,sparse_matrix), axis=1)\n",
    "xtrain_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report as clrp\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "classifier= LinearSVC(random_state=0, tol=1e-5) \n",
    "for train_index, test_index in kf.split(xtrain_matrix,ytrain_matrix):\n",
    "    classifier.fit(xtrain_matrix[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier.predict(xtrain_matrix[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier2 = XGBClassifier()\n",
    "for train_index, test_index in kf.split(xtrain_matrix,ytrain_matrix):\n",
    "    classifier2.fit(xtrain_matrix[train_index],ytrain_matrix[train_index])\n",
    "    ypred=classifier2.predict(xtrain_matrix[test_index])\n",
    "    ytestt=ytrain_matrix[test_index]\n",
    "    print(clrp(ytestt,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
